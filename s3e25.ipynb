{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "8NRJN4hAER3O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN9Aapu1CyTS",
        "outputId": "1385937d-f549-42b1-ec6e-52fd6f33a6b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp '/content/drive/MyDrive/kaggle.json' ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c playground-series-s3e25\n",
        "!unzip playground-series-s3e25.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('train.csv', index_col='id')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "s3IkE_40EO1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.isnull().any())\n",
        "print(f'Duplicates?: {data.duplicated().any()}')\n",
        "#data.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "qLkw00ykEqGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.hist()"
      ],
      "metadata": {
        "id": "x1GvNF8zF3h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "NuKrxXOrHMFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(data.corr(), annot=True)\n",
        "data.corr()"
      ],
      "metadata": {
        "id": "hsirbTSxLtY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data.drop(['atomicweight_Average', 'density_Average'], axis=1, inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "1Lx7lnT3Nyf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "# Loop through each column in the data\n",
        "for i, column in enumerate(data.columns):\n",
        "    # Create a subplot for each column\n",
        "    # The arguments are (nrows, ncols, index)\n",
        "    plt.subplot(2, 6, i+1)\n",
        "    sns.boxplot(y=data[column])\n",
        "    plt.title(column)\n",
        "\n",
        "plt.tight_layout()  # Adjusts the layout\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u51RSGCCOgAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "#winsorize(data.allelectrons_Total, limits=0.025, inplace=True)\n",
        "for i in data.columns.to_list():\n",
        "  if (i!='Hardness'):\n",
        "    winsorize(data[i], limits=0.1, inplace=True)"
      ],
      "metadata": {
        "id": "XdY2ZLQ-K93E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "y.head()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
      ],
      "metadata": {
        "id": "I2CTi8wEKR3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform the training data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert the scaled arrays back into pandas DataFrames\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)"
      ],
      "metadata": {
        "id": "EkrDjYxLTDz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled.head()"
      ],
      "metadata": {
        "id": "8Z-dxkBoUTSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting"
      ],
      "metadata": {
        "id": "6WwmlMXYmfi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 approach"
      ],
      "metadata": {
        "id": "wCOrEq5ppfVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluating the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'MAE: {mae}')\n",
        "print(f'MSE: {mse}')\n",
        "print(f'RMSE: {rmse}')\n",
        "print(f'R-squared: {r2}')\n"
      ],
      "metadata": {
        "id": "yG8JwUDnWpnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    'Ridge': Ridge(),\n",
        "    'Lasso': Lasso(),\n",
        "    'DecisionTree': DecisionTreeRegressor(),\n",
        "    'RandomForest': RandomForestRegressor(),\n",
        "    'GradientBoosting': GradientBoostingRegressor(),\n",
        "    'SVR': SVR(),\n",
        "    'MLPRegressor': MLPRegressor()\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    # Train model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    print(f'{name} trained.')\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Evaluate model\n",
        "    results[name] = {\n",
        "        'MAE': mean_absolute_error(y_test, y_pred),\n",
        "        'MSE': mean_squared_error(y_test, y_pred),\n",
        "        'RMSE': mean_squared_error(y_test, y_pred, squared=False),\n",
        "        'R2': r2_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "# Output results\n",
        "for name, metrics in results.items():\n",
        "    print(f'Results for {name}:')\n",
        "    for metric, value in metrics.items():\n",
        "        print(f'    {metric}: {value:.4f}')\n",
        "\n",
        "# Hyperparameter tuning for Random Forest\n",
        "parameters = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "rf_clf = GridSearchCV(RandomForestRegressor(), parameters, scoring='neg_mean_squared_error')\n",
        "rf_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Output best parameters and model\n",
        "print(f'Best parameters for Random Forest: {rf_clf.best_params_}')\n",
        "best_rf_model = rf_clf.best_estimator_\n",
        "\n",
        "# Evaluate the best Random Forest model\n",
        "best_rf_y_pred = best_rf_model.predict(X_test_scaled)\n",
        "print(f'Random Forest - MAE: {mean_absolute_error(y_test, best_rf_y_pred)}')\n",
        "print(f'Random Forest - MSE: {mean_squared_error(y_test, best_rf_y_pred)}')\n",
        "print(f'Random Forest - RMSE: {mean_squared_error(y_test, best_rf_y_pred, squared=False)}')\n",
        "print(f'Random Forest - R2: {r2_score(y_test, best_rf_y_pred)}')\n"
      ],
      "metadata": {
        "id": "FO6NF39YXe_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the test data\n",
        "test_data = pd.read_csv('test.csv')\n",
        "test_data.drop(['atomicweight_Average', 'density_Average'], axis=1, inplace=True)\n",
        "\n",
        "# Step 2: Preprocess and scale the test data\n",
        "# (Assuming that 'id' is the first column and should not be scaled)\n",
        "test_features = test_data.iloc[:, 1:]  # Exclude 'id' column\n",
        "test_features_scaled = scaler.transform(test_features)  # Use the same scaler as before\n",
        "\n",
        "# Step 3: Predict 'Hardness' using the best model\n",
        "test_predictions = best_rf_model.predict(test_features_scaled)\n",
        "\n",
        "# Step 4: Create a submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'Hardness': test_predictions\n",
        "})\n",
        "\n",
        "# Step 5: Save the predictions to a CSV file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# Step 6: Submit the predictions to Kaggle\n",
        "# kaggle competitions submit -c playground-series-s3e25 -f submission.csv -m \"Message\""
      ],
      "metadata": {
        "id": "eBlI8H_rbsnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 approach"
      ],
      "metadata": {
        "id": "pXszfOhTpiR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define a parameter grid to search over\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize the XGBoost regressor\n",
        "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', device='cuda')\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb_reg,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_mean_squared_error',  # You can choose a different scorer\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    n_jobs=-1  # Use all available cores\n",
        ")\n",
        "\n",
        "# Fit GridSearchCV on the training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Find the best parameters and the best estimator\n",
        "best_parameters = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(f'Best parameters found: {best_parameters}')\n",
        "\n",
        "# You can now evaluate the best_model on your test data and proceed with the predictions"
      ],
      "metadata": {
        "id": "nGRBw-Z3dfYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming the scaler has been previously fitted on the training data\n",
        "# and best_xgb_model is the best model obtained from GridSearchCV\n",
        "\n",
        "# Step 1: Load the test data\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Optional: If you need to drop certain columns as per preprocessing done during training\n",
        "#test_data.drop(['atomicweight_Average', 'density_Average'], axis=1, inplace=True)\n",
        "\n",
        "# Step 2: Preprocess and scale the test data\n",
        "# (Assuming that 'id' is the first column and should not be scaled)\n",
        "test_features = test_data.iloc[:, 1:]  # Exclude 'id' column\n",
        "test_features_scaled = scaler.transform(test_features)  # Use the same scaler as before\n",
        "\n",
        "# Step 3: Predict 'Hardness' using the best XGBoost model\n",
        "test_predictions = best_model.predict(test_features_scaled)\n",
        "\n",
        "# Step 4: Create a submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],  # Ensure this is the correct identifier column from your test set\n",
        "    'Hardness': test_predictions\n",
        "})\n",
        "\n",
        "# Step 5: Save the predictions to a CSV file\n",
        "submission.to_csv('xgb_submission_1.csv', index=False)\n",
        "\n",
        "# The last step is to submit the predictions to Kaggle using the command line interface\n",
        "# The command to submit to Kaggle would be run in your terminal, not in Python.\n",
        "# Example command:\n",
        "# kaggle competitions submit -c playground-series-s3e25 -f xgb_submission.csv -m \"XGB Model Predictions\"\n"
      ],
      "metadata": {
        "id": "V52bKlgPg9jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, median_absolute_error\n",
        "\n",
        "# Make sure the training data is loaded and preprocessed (X_train_scaled, y_train)\n",
        "\n",
        "# Step 1: Define the scorer based on Median Absolute Error\n",
        "medae_scorer = make_scorer(median_absolute_error, greater_is_better=False)\n",
        "\n",
        "# Step 2: Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "# Step 3: Initialize the GridSearchCV\n",
        "xgb_model = XGBRegressor(objective='reg:squarederror', device='cuda')\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid,\n",
        "                           scoring=medae_scorer, cv=5, verbose=2)\n",
        "\n",
        "# Step 4: Fit the GridSearchCV to the training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 5: Print the best parameters and the best score\n",
        "print(f'Best parameters found: {grid_search.best_params_}')\n",
        "print(f'Best Median Absolute Error: {-grid_search.best_score_}')\n",
        "\n",
        "# Step 6: Use the best estimator to make predictions on the test set\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "test_features = test_data.iloc[:, 1:]  # Exclude 'id' column\n",
        "test_features_scaled = scaler.transform(test_features)  # Use the same scaler as before\n",
        "\n",
        "test_predictions = best_xgb_model.predict(test_features_scaled)\n",
        "\n",
        "# Create the submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],  # Replace with the correct 'id' column from your test set\n",
        "    'Hardness': test_predictions\n",
        "})\n",
        "\n",
        "# Save the submission file\n",
        "submission.to_csv('xgb_submission.csv', index=False)\n",
        "\n",
        "# Use the following command in your terminal to submit to Kaggle, not in Python\n",
        "# kaggle competitions submit -c playground-series-s3e25 -f xgb_submission.csv -m \"XGBRegressor with GridSearch\"\n"
      ],
      "metadata": {
        "id": "PpNwQjryftzs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}